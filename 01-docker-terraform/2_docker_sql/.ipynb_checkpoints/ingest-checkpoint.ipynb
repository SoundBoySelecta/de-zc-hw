{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8a8d0f4-df35-47ba-99c0-eb7033ec117d",
   "metadata": {},
   "source": [
    "<hr style=\"border: 5px solid lightblue\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bf48c5-c591-441d-80b7-3fbece9047d4",
   "metadata": {},
   "source": [
    "j) Import needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1c0cc09-538b-4fb5-81f8-20454eb1eecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dt/j6n_44y57c9595rlg_6rf5lm0000gn/T/ipykernel_7388/2976241132.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a593fe76-8347-4236-af46-36576702414a",
   "metadata": {},
   "source": [
    "<hr style=\"border: 5px solid lightblue\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384742be-73ec-40b5-8182-e6ef9355fbc6",
   "metadata": {},
   "source": [
    "k) Set data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b136256d-abec-4a3b-8081-6c7d9f7dd464",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5932668c-246a-457a-97b0-668335e66417",
   "metadata": {},
   "source": [
    "<hr style=\"border: 5px solid lightblue\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3896313-3851-446d-b5f2-59c282c8aef1",
   "metadata": {},
   "source": [
    "Set trip and zone data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f35b2ef-6fa8-4e53-b2d2-b52531e4fa33",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_data = 'green_tripdata_2019-09.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "529ff789-6bab-47ae-a7f3-1faa006c63c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "zone_data = 'taxi+_zone_lookup.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07338068-eb7c-4a1b-8e51-e12a70fe5099",
   "metadata": {},
   "source": [
    "<hr style=\"border: 5px solid lightblue\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bdfd85-2a0e-4715-8149-50a9c584cfbc",
   "metadata": {},
   "source": [
    "l) Import zone data into pandas (chunks not needed not a large file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "167036fa-f6bf-4f52-8fcf-336b5a1b5941",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zone_data = pd.read_csv(filepath_or_buffer=data_dir+zone_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc286dcf-a224-4bd5-be81-dcb0ee23cdd5",
   "metadata": {},
   "source": [
    "View zone df shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "eb8729d6-d929-43c9-b912-db1219b47083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe rows: 265, Dataframe columns: 4\n"
     ]
    }
   ],
   "source": [
    "print(f'Dataframe rows: {df_zone_data.shape[0]}, Dataframe columns: {df_zone_data.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d06404-ab20-4040-ae3d-fa4ed52766af",
   "metadata": {},
   "source": [
    "Import trip data into pandas (chunks needed since large file, more to simulate batch processing as 400k is managable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ad6f84-e0af-4bfe-8a98-5884c13011b8",
   "metadata": {},
   "source": [
    "Create a column list and remove 100% null value columns (ehail_fee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d7815e0b-9225-4400-914d-7f50973a6638",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_cols= ['VendorID',\n",
    " 'lpep_pickup_datetime',\n",
    " 'lpep_dropoff_datetime',\n",
    " 'store_and_fwd_flag',\n",
    " 'RatecodeID',\n",
    " 'PULocationID',\n",
    " 'DOLocationID',\n",
    " 'passenger_count',\n",
    " 'trip_distance',\n",
    " 'fare_amount',\n",
    " 'extra',\n",
    " 'mta_tax',\n",
    " 'tip_amount',\n",
    " 'tolls_amount',\n",
    " 'improvement_surcharge',\n",
    " 'total_amount',\n",
    " 'payment_type',\n",
    " 'trip_type',\n",
    " 'congestion_surcharge']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dd2c05-8c5e-4d1f-a8ad-02e552b43290",
   "metadata": {},
   "source": [
    "Create iterable to import in chunks, this does not create a df, but an iterable object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "990f86d2-c9d7-4d8d-8d12-d397cd8b6cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_data_iterable_in_100k_chunks = pd.read_csv(filepath_or_buffer=data_dir+trip_data, iterator=True, chunksize=100000, parse_dates=['lpep_pickup_datetime', 'lpep_dropoff_datetime'], usecols=keep_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41299b9d-60d1-4900-a2dc-3f3007b799c5",
   "metadata": {},
   "source": [
    "Verify type of the itertable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "80dcc174-c066-4e96-987d-94295149e0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.io.parsers.readers.TextFileReader'>\n"
     ]
    }
   ],
   "source": [
    "print(type(trip_data_iterable_in_100k_chunks))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccdfc94-f56b-4946-8974-331eddeeeb3f",
   "metadata": {},
   "source": [
    "Iterate over the first 100K rows (this is a df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "961071d7-4fb3-4dbe-974f-569ebc1356a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trip_data_in_100k_chunks = next(trip_data_iterable_in_100k_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe372d1-bcae-4f93-b08e-97993f226fa9",
   "metadata": {},
   "source": [
    "Verify first chunk is type dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a3c0582f-2065-447d-a97f-ec8d8fe0f220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(df_trip_data_in_100k_chunks))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d3833a-1f33-4484-99fc-571bb743967a",
   "metadata": {},
   "source": [
    "Verify shape (Remember original csv had 20 columns, we dropped the 'ehail_fee' which was empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "34f710ae-6c80-4613-a768-a289407326c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe rows: 100000, Dataframe columns: 19\n"
     ]
    }
   ],
   "source": [
    "print(f'Dataframe rows: {df_trip_data_in_100k_chunks.shape[0]}, Dataframe columns: {df_trip_data_in_100k_chunks.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3960ae5a-7d26-464d-aaa9-b175d4710053",
   "metadata": {},
   "source": [
    "<hr style=\"border: 5px solid blue\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4059fcf0-7f81-470e-8688-67175f82316e",
   "metadata": {},
   "source": [
    "Open a connection the the postgres db ny_green_taxi, using url: 'dialect+driver://username:password@host:port/database', this will not work until u invoke engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5c39624f-fae5-4d8d-b476-19102d94555e",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\"postgresql://root:root@localhost:5432/ny_green_taxi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "013ab391-53ad-4aa8-b9ac-9a888b40d7b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.base.Connection at 0x127c94a90>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd13d91c-836e-4516-8933-0742250d0925",
   "metadata": {},
   "source": [
    "m) Create a table from dataframe and name it \"ny_green_taxi\" database, remember this command doesnt do any interaction with Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a37fa61e-9f7e-4b38-82d9-033ab48d1a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CREATE TABLE ny_green_taxi (\n",
      "\t\"VendorID\" BIGINT, \n",
      "\tlpep_pickup_datetime TIMESTAMP WITHOUT TIME ZONE, \n",
      "\tlpep_dropoff_datetime TIMESTAMP WITHOUT TIME ZONE, \n",
      "\tstore_and_fwd_flag TEXT, \n",
      "\t\"RatecodeID\" BIGINT, \n",
      "\t\"PULocationID\" BIGINT, \n",
      "\t\"DOLocationID\" BIGINT, \n",
      "\tpassenger_count BIGINT, \n",
      "\ttrip_distance FLOAT(53), \n",
      "\tfare_amount FLOAT(53), \n",
      "\textra FLOAT(53), \n",
      "\tmta_tax FLOAT(53), \n",
      "\ttip_amount FLOAT(53), \n",
      "\ttolls_amount FLOAT(53), \n",
      "\timprovement_surcharge FLOAT(53), \n",
      "\ttotal_amount FLOAT(53), \n",
      "\tpayment_type BIGINT, \n",
      "\ttrip_type BIGINT, \n",
      "\tcongestion_surcharge FLOAT(53)\n",
      ")\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pd.io.sql.get_schema(df_trip_data_in_100k_chunks, name=\"ny_green_taxi\", con=engine))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcdb6c6-5314-43e8-884a-a175c2aefeeb",
   "metadata": {},
   "source": [
    "Load the first 100k rows into the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "67e5ac6b-470e-4349-8016-2f50da987830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trip_data_in_100k_chunks.to_sql(name=\"ny_green_taxi\", con=engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8611a36-6036-4fa9-aba6-7164c567d2f1",
   "metadata": {},
   "source": [
    "o) Add the rest of the data in 100k row chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6b73d2d6-cf4e-42d8-8880-6aab3f8f41bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "af21bc61-f490-41c1-97e8-0c117d0ea1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted another chunk, took 13.973 second\n",
      "Inserted another chunk, took 15.419 second\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dt/j6n_44y57c9595rlg_6rf5lm0000gn/T/ipykernel_7388/1276191877.py:3: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_trip_data_in_100k_chunks = next(trip_data_iterable_in_100k_chunks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted another chunk, took 15.465 second\n",
      "Inserted another chunk, took 6.456 second\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m      2\u001b[0m     t_start \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m----> 3\u001b[0m     df_trip_data_in_100k_chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrip_data_iterable_in_100k_chunks\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m      4\u001b[0m     df_trip_data_in_100k_chunks\u001b[38;5;241m.\u001b[39mto_sql(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mny_green_taxi\u001b[39m\u001b[38;5;124m\"\u001b[39m, con\u001b[38;5;241m=\u001b[39mengine, if_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mappend\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m     t_end \u001b[38;5;241m=\u001b[39m time()\n",
      "File \u001b[0;32m~/code/de-zc-hw/2_docker_sql/venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1841\u001b[0m, in \u001b[0;36mTextFileReader.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1839\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m   1840\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1841\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1842\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m   1843\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/code/de-zc-hw/2_docker_sql/venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1983\u001b[0m, in \u001b[0;36mTextFileReader.get_chunk\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m   1981\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[1;32m   1982\u001b[0m     size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnrows \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_currow)\n\u001b[0;32m-> 1983\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/de-zc-hw/2_docker_sql/venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1921\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1914\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1915\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1916\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1917\u001b[0m     (\n\u001b[1;32m   1918\u001b[0m         index,\n\u001b[1;32m   1919\u001b[0m         columns,\n\u001b[1;32m   1920\u001b[0m         col_dict,\n\u001b[0;32m-> 1921\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1923\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1925\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/code/de-zc-hw/2_docker_sql/venv/lib/python3.11/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32mparsers.pyx:863\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    t_start = time()\n",
    "    df_trip_data_in_100k_chunks = next(trip_data_iterable_in_100k_chunks) \n",
    "    df_trip_data_in_100k_chunks.to_sql(name=\"ny_green_taxi\", con=engine, if_exists='append')\n",
    "    t_end = time()\n",
    "    print('Inserted another chunk, took %.3f second' %(t_end - t_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69b24f0-03b4-41c3-bb95-bf7e89fabaa6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
